{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshay\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "data = pd.read_csv('hotel_reviews.csv')\n",
    "#data[\"is_bad_review\"] = data[\"Rating\"].apply(lambda x: 1 if x <=3 else 0)\n",
    "data[\"is_bad_review\"] = data[\"Rating\"].apply(lambda x: 1 if x>3 else 0 if x<3 else 2)\n",
    "\n",
    "\n",
    "\n",
    "data['word_count'] = data['Review'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "data['char_count'] = data['Review'].str.len() ## this also includes spaces\n",
    "\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['Review'].apply(lambda x: avg_word(x))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stopwords'] = data['Review'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "data['hastags'] = data['Review'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "\n",
    "data['numerics'] = data['Review'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "data['Review'] = data['Review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "data['Review'] = data['Review'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['Review'] = data['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "data['word_count_after_punct'] = data['Review'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "bow_vector = CountVectorizer()\n",
    "\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(lowercase=True,max_features=1000,stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['Review'] # the features we want to analyze\n",
    "ylabels = data['is_bad_review'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.4)\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame(X_test)\n",
    "test_df.to_csv('test_preprocessed.csv')\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "# Create pipeline using Bag of Words\n",
    "pipeline = Pipeline(steps=[(\"tfid_vector\", TfidfVectorizer(lowercase=True,\n",
    "                                                     max_features=1000,\n",
    "                                                     stop_words=ENGLISH_STOP_WORDS)),\n",
    "                     ('clf',LogisticRegression())])\n",
    "\n",
    "# model generalf._vectorizer = clf\n",
    "bow_vector.fit(X_train,y_train)\n",
    "pipeline.fit(X_train,y_train)\n",
    "#ypred =clf.predict(X_test)\n",
    "\n",
    "\n",
    "from joblib import dump\n",
    "dump(pipeline, filename=\"model.joblib\")\n",
    "# Saving model to disk\n",
    "pickle.dump(pipeline, open('model.pkl','wb'))\n",
    "# Loading model to compare the results\n",
    "model = pickle.load(open('model.pkl','rb'))\n",
    "print(model.predict([('Good Nice')]))\n",
    "print(model.predict([('Bad')]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
